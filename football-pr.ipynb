{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7497 - loss: 0.5180 - val_accuracy: 0.7726 - val_loss: 0.4714\n",
      "Epoch 2/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7816 - loss: 0.4601 - val_accuracy: 0.7741 - val_loss: 0.4662\n",
      "Epoch 3/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7798 - loss: 0.4615 - val_accuracy: 0.7756 - val_loss: 0.4645\n",
      "Epoch 4/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7793 - loss: 0.4545 - val_accuracy: 0.7736 - val_loss: 0.4648\n",
      "Epoch 5/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7843 - loss: 0.4505 - val_accuracy: 0.7749 - val_loss: 0.4615\n",
      "Epoch 6/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7899 - loss: 0.4431 - val_accuracy: 0.7769 - val_loss: 0.4603\n",
      "Epoch 7/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7870 - loss: 0.4422 - val_accuracy: 0.7740 - val_loss: 0.4621\n",
      "Epoch 8/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7850 - loss: 0.4457 - val_accuracy: 0.7734 - val_loss: 0.4619\n",
      "Epoch 9/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7862 - loss: 0.4412 - val_accuracy: 0.7767 - val_loss: 0.4625\n",
      "Epoch 10/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.4384 - val_accuracy: 0.7766 - val_loss: 0.4630\n",
      "Epoch 11/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.4428 - val_accuracy: 0.7766 - val_loss: 0.4631\n",
      "Epoch 12/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7918 - loss: 0.4319 - val_accuracy: 0.7763 - val_loss: 0.4672\n",
      "Epoch 13/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7862 - loss: 0.4388 - val_accuracy: 0.7743 - val_loss: 0.4665\n",
      "Epoch 14/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7869 - loss: 0.4382 - val_accuracy: 0.7773 - val_loss: 0.4644\n",
      "Epoch 15/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7862 - loss: 0.4371 - val_accuracy: 0.7767 - val_loss: 0.4651\n",
      "Epoch 16/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7876 - loss: 0.4356 - val_accuracy: 0.7769 - val_loss: 0.4683\n",
      "Epoch 17/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7876 - loss: 0.4347 - val_accuracy: 0.7774 - val_loss: 0.4676\n",
      "Epoch 18/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7868 - loss: 0.4350 - val_accuracy: 0.7759 - val_loss: 0.4665\n",
      "Epoch 19/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.4295 - val_accuracy: 0.7786 - val_loss: 0.4661\n",
      "Epoch 20/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7881 - loss: 0.4348 - val_accuracy: 0.7774 - val_loss: 0.4686\n",
      "Epoch 21/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7918 - loss: 0.4342 - val_accuracy: 0.7772 - val_loss: 0.4711\n",
      "Epoch 22/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7856 - loss: 0.4353 - val_accuracy: 0.7766 - val_loss: 0.4691\n",
      "Epoch 23/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.4319 - val_accuracy: 0.7792 - val_loss: 0.4693\n",
      "Epoch 24/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7885 - loss: 0.4313 - val_accuracy: 0.7765 - val_loss: 0.4711\n",
      "Epoch 25/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7914 - loss: 0.4276 - val_accuracy: 0.7773 - val_loss: 0.4699\n",
      "Epoch 26/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.4262 - val_accuracy: 0.7765 - val_loss: 0.4695\n",
      "Epoch 27/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7905 - loss: 0.4287 - val_accuracy: 0.7762 - val_loss: 0.4709\n",
      "Epoch 28/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7876 - loss: 0.4328 - val_accuracy: 0.7761 - val_loss: 0.4721\n",
      "Epoch 29/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7889 - loss: 0.4325 - val_accuracy: 0.7751 - val_loss: 0.4737\n",
      "Epoch 30/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7881 - loss: 0.4317 - val_accuracy: 0.7765 - val_loss: 0.4719\n",
      "Epoch 31/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.4319 - val_accuracy: 0.7776 - val_loss: 0.4716\n",
      "Epoch 32/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7926 - loss: 0.4282 - val_accuracy: 0.7765 - val_loss: 0.4732\n",
      "Epoch 33/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7896 - loss: 0.4330 - val_accuracy: 0.7772 - val_loss: 0.4723\n",
      "Epoch 34/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.4256 - val_accuracy: 0.7765 - val_loss: 0.4724\n",
      "Epoch 35/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7895 - loss: 0.4309 - val_accuracy: 0.7790 - val_loss: 0.4737\n",
      "Epoch 36/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7907 - loss: 0.4308 - val_accuracy: 0.7777 - val_loss: 0.4736\n",
      "Epoch 37/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7899 - loss: 0.4299 - val_accuracy: 0.7773 - val_loss: 0.4726\n",
      "Epoch 38/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7889 - loss: 0.4303 - val_accuracy: 0.7770 - val_loss: 0.4739\n",
      "Epoch 39/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7914 - loss: 0.4275 - val_accuracy: 0.7771 - val_loss: 0.4727\n",
      "Epoch 40/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7930 - loss: 0.4239 - val_accuracy: 0.7770 - val_loss: 0.4731\n",
      "Epoch 41/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7895 - loss: 0.4279 - val_accuracy: 0.7794 - val_loss: 0.4745\n",
      "Epoch 42/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7890 - loss: 0.4330 - val_accuracy: 0.7766 - val_loss: 0.4732\n",
      "Epoch 43/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7913 - loss: 0.4245 - val_accuracy: 0.7790 - val_loss: 0.4728\n",
      "Epoch 44/44\n",
      "\u001b[1m1200/1200\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7853 - loss: 0.4290 - val_accuracy: 0.7786 - val_loss: 0.4756\n",
      "\u001b[1m300/300\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7846 - loss: 0.4663\n",
      "Final Accuracy (Win Prediction): 0.7786\n",
      "ðŸ“Š Final MAE (Win Prediction): 0.2214\n",
      "ðŸ† Predicted Home Win Probability: 58.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitro\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "# File Paths\n",
    "base_dir = r\"C:\\Users\\Nitro\\Downloads\"\n",
    "results_file = os.path.join(base_dir, \"results.csv\")\n",
    "name_changes_file = os.path.join(base_dir, \"former_names.csv\")\n",
    "\n",
    "# Load Data\n",
    "results = pd.read_csv(results_file)\n",
    "name_changes = pd.read_csv(name_changes_file)\n",
    "\n",
    "# Standardize Team Names\n",
    "name_changes = name_changes.rename(columns={\"former\": \"old_name\", \"current\": \"new_name\"})\n",
    "for col in ['home_team', 'away_team']:\n",
    "    results = results.merge(name_changes[['old_name', 'new_name']], \n",
    "                            left_on=col, right_on=\"old_name\", how=\"left\")\n",
    "    results[col] = results[\"new_name\"].combine_first(results[col])\n",
    "    results.drop(columns=['old_name', 'new_name'], inplace=True)\n",
    "\n",
    "# Validate Columns\n",
    "required_columns = ['date', 'home_team', 'away_team', 'home_score', 'away_score', 'tournament', 'city', 'country', 'neutral']\n",
    "missing_cols = [col for col in required_columns if col not in results.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing columns in results.csv: {missing_cols}\")\n",
    "\n",
    "# Feature Engineering\n",
    "results['goal_diff'] = results['home_score'] - results['away_score']\n",
    "results['year'] = pd.to_datetime(results['date']).dt.year\n",
    "results['match_result'] = results['goal_diff'].apply(lambda x: 0 if x > 0 else (1 if x == 0 else 2))\n",
    "\n",
    "# Rolling Win/Draw/Loss Rates\n",
    "def rolling_avg(team_col, result_col, value):\n",
    "    return results.groupby(team_col)[result_col].transform(lambda x: (x == value).rolling(5, min_periods=1).mean())\n",
    "\n",
    "results['home_win_rate'] = rolling_avg('home_team', 'match_result', 0)\n",
    "results['home_draw_rate'] = rolling_avg('home_team', 'match_result', 1)\n",
    "results['home_loss_rate'] = rolling_avg('home_team', 'match_result', 2)\n",
    "results['away_win_rate'] = rolling_avg('away_team', 'match_result', 2)\n",
    "results['away_draw_rate'] = rolling_avg('away_team', 'match_result', 1)\n",
    "results['away_loss_rate'] = rolling_avg('away_team', 'match_result', 0)\n",
    "\n",
    "# Home Advantage\n",
    "results['home_advantage'] = results['neutral'].apply(lambda x: 0 if x else 1)\n",
    "\n",
    "# One-Hot Encoding\n",
    "results = pd.get_dummies(results, columns=['tournament', 'city', 'country'])\n",
    "\n",
    "# Team Encoding\n",
    "teams = pd.concat([results['home_team'], results['away_team']]).unique()\n",
    "team_map = {name: idx for idx, name in enumerate(teams)}\n",
    "results['home_team_id'] = results['home_team'].map(team_map)\n",
    "results['away_team_id'] = results['away_team'].map(team_map)\n",
    "num_teams = len(team_map)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = ['year', 'home_win_rate', 'home_draw_rate', 'home_loss_rate',\n",
    "                   'away_win_rate', 'away_draw_rate', 'away_loss_rate', 'home_advantage']\n",
    "results[scaled_features] = scaler.fit_transform(results[scaled_features])\n",
    "\n",
    "# Train-Test Split\n",
    "train_data, val_data = train_test_split(results, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = train_data[['home_team_id', 'away_team_id'] + scaled_features]\n",
    "y_train = keras.utils.to_categorical(train_data['match_result'], num_classes=3)\n",
    "\n",
    "X_val = val_data[['home_team_id', 'away_team_id'] + scaled_features]\n",
    "y_val = keras.utils.to_categorical(val_data['match_result'], num_classes=3)\n",
    "\n",
    "# Neural Network Model\n",
    "home_input = keras.layers.Input(shape=(1,), name='home_team')\n",
    "away_input = keras.layers.Input(shape=(1,), name='away_team')\n",
    "numeric_input = keras.layers.Input(shape=(len(scaled_features),), name='numeric_features')\n",
    "\n",
    "embedding_size = int(np.sqrt(num_teams))  \n",
    "home_embed = keras.layers.Embedding(input_dim=num_teams, output_dim=embedding_size)(home_input)\n",
    "away_embed = keras.layers.Embedding(input_dim=num_teams, output_dim=embedding_size)(away_input)\n",
    "\n",
    "home_flat = keras.layers.Flatten()(home_embed)\n",
    "away_flat = keras.layers.Flatten()(away_embed)\n",
    "\n",
    "concat = keras.layers.Concatenate()([home_flat, away_flat, numeric_input])\n",
    "\n",
    "dense = keras.layers.Dense(128, activation='swish', kernel_regularizer=keras.regularizers.l2(0.0001))(concat)\n",
    "dense = keras.layers.Dropout(0.2)(dense)\n",
    "dense = keras.layers.Dense(64, activation='swish', kernel_regularizer=keras.regularizers.l2(0.0001))(dense)\n",
    "dense = keras.layers.Dropout(0.2)(dense)\n",
    "dense = keras.layers.Dense(32, activation='swish')(dense)\n",
    "\n",
    "output = keras.layers.Dense(3, activation=\"softmax\", name=\"match_result\")(dense)\n",
    "\n",
    "# Compile Model\n",
    "model = keras.Model(inputs=[home_input, away_input, numeric_input], outputs=output)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "model.fit({'home_team': X_train['home_team_id'], 'away_team': X_train['away_team_id'], 'numeric_features': X_train[scaled_features]},\n",
    "          y_train,\n",
    "          epochs=44, batch_size=32, verbose=1, \n",
    "          validation_data=({'home_team': X_val['home_team_id'], 'away_team': X_val['away_team_id'], 'numeric_features': X_val[scaled_features]}, \n",
    "                           y_val))\n",
    "\n",
    "# Evaluate Model\n",
    "val_results = model.evaluate({'home_team': X_val['home_team_id'], 'away_team': X_val['away_team_id'], 'numeric_features': X_val[scaled_features]}, \n",
    "                             y_val, verbose=1)\n",
    "\n",
    "print(f\"Final Accuracy: {val_results[1]:.4f}\")\n",
    "\n",
    "# Prediction Function\n",
    "def predict_match(home_team_name, away_team_name, match_year):\n",
    "    home_team = team_map.get(home_team_name, -1)\n",
    "    away_team = team_map.get(away_team_name, -1)\n",
    "\n",
    "    if home_team == -1 or away_team == -1:\n",
    "        print(f\"Error: Unknown team - {home_team_name if home_team == -1 else away_team_name}\")\n",
    "        return\n",
    "\n",
    "    home_win_rate = results[results['home_team'] == home_team_name]['home_win_rate'].mean()\n",
    "    home_draw_rate = results[results['home_team'] == home_team_name]['home_draw_rate'].mean()\n",
    "    home_loss_rate = results[results['home_team'] == home_team_name]['home_loss_rate'].mean()\n",
    "\n",
    "    away_win_rate = results[results['away_team'] == away_team_name]['away_win_rate'].mean()\n",
    "    away_draw_rate = results[results['away_team'] == away_team_name]['away_draw_rate'].mean()\n",
    "    away_loss_rate = results[results['away_team'] == away_team_name]['away_loss_rate'].mean()\n",
    "\n",
    "    input_data = {'home_team': np.array([home_team]), 'away_team': np.array([away_team]), \n",
    "                  'numeric_features': scaler.transform(np.array([[match_year, home_win_rate, home_draw_rate, home_loss_rate, \n",
    "                                                                  away_win_rate, away_draw_rate, away_loss_rate, 1]]))}\n",
    "\n",
    "    prediction = model.predict(input_data, verbose=0)\n",
    "    win_prob, draw_prob, loss_prob = prediction[0]\n",
    "\n",
    "    print(f\"Home Win Probability: {win_prob*100:.2f}%\")\n",
    "    print(f\"Draw Probability: {draw_prob*100:.2f}%\")\n",
    "    print(f\"Away Win Probability: {loss_prob*100:.2f}%\")\n",
    "\n",
    "# Example Prediction\n",
    "predict_match(\"Germany\", \"France\", 2025)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
